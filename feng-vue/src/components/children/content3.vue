<template>
  <div class="article">
    <div class="title-main">
      <h2 class="title">数据调度挖掘技术研究----高效提取数据中的价值</h2>
      <div class="time">2018-11-14 09:52:05</div>
    </div>
    <div class="content">
      <p>随着互联网的快速发展，以及云计算技术的推广，海量数据不断产生。
        对于企业而言，这些海量数据变得越来越难处理。
        对于传统的基于关系型数据库（RDS）架构的数据分析系统，当单表数据数据超过千万，
        对于RDS的压力就会呈指数增加，最主要的表现体现在IOPS的增加和CPU使用率的提升。
        严重的情况会影响正常业务的进行。</p>
      <p>我们公司在提取数据中的价值这个问题上有三个阶段：第一阶段是单一数据库阶段，这个时候由于用户数不多，
        每天的业务数据不大，可以直接在生产库中查询，当时也没有设计多业务表之间的连表查询，对数据库的压力不大，
        因此就算在生产库中查询也不会有任何问题；第二阶段，读写分离阶段，这一阶段的显著特征是数据量的增加，
        数据表之间的连表查询需求越来越大，如果直接生产库中查询，对生产库的压力非常大，
        很容易就会影响生产库正常的读写任务；第三阶段是分布式存储以及存储计算分离阶段，
        该阶段的主要特点是将生产库和BI库分离，将存储和计算分离，在保证业务正常的情况下，提高提取数据高效性。
      </p>
      <p style="font-weight: bold">1、数据加工的流程</p>
      <p>
        图1是数据加工流程，首先客户端采集数据，将数据根据需要保存于日志服务、业务数据库、服务器缓存中。
        从图1而已看出，服务器缓存、业务数据库、业务服务器之间的数据是可以双向，
        业务服务器根据需求选择从缓存还是从数据库中取数据。
      </p>
      <p>
        前面是业务数据的高效加工，下面是分析数据的高效挖掘。
        首先将数据按数据量以及数据及时性的要求将数据定时从日志服务、业务数据库中同步到分布式文件存储中。
        计算集群可以按照需求分配CPU核心数以及内存数通过hive sql 从存储中提取数据并计算，
        之后写回分布式存储中。最后将加工后的最终结果数据同步到数据库中，方便现有的BI报表系统处理这些结果数据，
        提高BI系统效率。
      </p>
      <img src="../../img/dataSls/data1.jpg" />
      <p style="font-weight: bold">2、数据计算的处理方法</p>
      <p>图2是数据处理的思维导图，将数据的处理分为了五种。</p>
      <img src="../../img/dataSls/data2.jpg" />
      <p style="font-weight: bold">2.1、数据的预处理</p>
      <p>
        将数据从不同的数据源同步到hadoop中，此时根据业务场景需要按分钟、按小时、按天、甚至按月同步。
        从日志服务中同步数据，是根据日志文件，按文件投递到hadoop中，一般都是按照文件的预计的大小，
        将文件细分到分钟。比如某个日志文件保存了从2017-12-01 00:00:00 到 2017-12-01 00:30:00 的日志数据，
        则将文件名命名为XXXX201712010030，在投递时将该文件按照hadoop文件格式投递到hadoop中，
        同时在hadoop中设置好字段类型，将不符合的数据清洗掉。
      </p>
      <p>
        如果数据是从数据库中同步到hadoop中，则首先需要将数据库的该表加上create_time索引，
        保证数据在同步时能够用到该索引，减少单次同步查询数据库时的压力，另外增加id索引，通过分布式同步，
        提高同步效率。一般情况下单日千万级的表格可以考虑5分钟同步一次，减少单次同步时的慢查询，
        百万级的表格可以考虑分小时同步，十万级的表格可以考虑按天同步。
      </p>
      <p>
        在这一步中，也会进行一部分脏数据的处理，将不符合数据类型的数据行直接删除，
        或者在同步过程中添加筛选条件，将某些列为空的数据也进行删除（不过这一步操作会比较谨慎，
        有时候会在数据多级处理中将为空或者异常值进行处理）。
      </p>
      <p style="font-weight: bold">2.2、数据的冗余处理</p>
      <p>
        在hadoop中重要列进行提取，保存到单独表中，方便处理。比如用户登录记录表，
        将用户部分信息提取出来，保存到单日活跃用户表，去除了多次登录用户的记录，
        虽然这部分记录在用户登录记录表中依旧有保存，但是单独保存表以后方便后续查询，提高效率。
      </p>
      <p>
        在Mysql与hadoop中同时保存多天的历史数据。Mysql单库对分布式的支持并不理想，
        因此在mysql中一般对于日志数据仅能保存近几天的数据，因此我再hadoop中对mysql中的日志数据进行永久保存，
        如果需要，可以将hadoop的数据同步回mysql。
      </p>
      <p>
        有时候单条日志数据可能会存在某一列保存了多条记录的情况。
        比如用户登录设备表，一个用户会有多条登录设备，RDS要求数据尽量不要冗余，
        因此会将多个设备保存到一个字段中，对于程序来判断某个设备是否在该用户常用设备下确实是没问题，
        但是如果是要数据分析，写sql的话难度比较大。并且在hadoop中廉价的存储成本允许你可以有一定的冗余。
        因此我会通过SPLIT()以后将数据LATERAL VIEW EXPLODE，这样方便计算，提高计算效率。
      </p>
      <p style="font-weight: bold">
        2.3、数据的多级处理
      </p>
      <p>将不同粒度的数据分层次处理，比如我想知道当天我们的活跃用户有多少，
        我不会直接给出当天活跃用户数，而是先给一个分省分运营商的活跃用户数，再给一个分省的活跃用户，
        再给一个分运营商的活跃用户，最后再给总的活跃用户数。如图3所示。
      </p>
      <img src="../../img/dataSls/data3.jpg" />
      <p>
        当然这种分粒度多级统计出来的结果也是需要跟业务逻辑配合的，例如一个用户安装了多款游戏，
        如果说按照分游戏先统计出一个活跃用户，然后再按照分游戏的活跃用户求和得到总活跃用户，
        那得到的真实的活跃用户就会偏多，但是有时候我们就是需要这样一个活跃用户，
        就是将同一个用户玩不同的游戏算成多个用户。这样做的好处有：1、在合理范围内增加我们公司活跃用户总数；
        2、能够得到一个真实的用户arpu值。
      </p>
      <p style="font-weight: bold">
        2.4、数据的分类处理
      </p>
      <p>
        开发为了减少开发的工作量，尤其是服务端开发，经常讲不同的type或者不同的behavior_id写入一张表中，
        这样由于不需要判断具体是什么类型的日志数据就可以直接插入数据库中，提高了数据插入的性能。
      </p>
      <p>
        我们在处理这一部分的数据时，如果类型不多，可以将这部分类型穷举，分列统计后放在结果表中，
        但是如果类型很多，一般都是直接将这些类型group by，然后统计计算，放在结果表中，当BI报表需要用到时，
        提取需要的类型，进行报表展示。
      </p>
      <p style="font-weight: bold">
        2.5、数据的分类处理
      </p>
      <p>
        将结果表同步到BI数据库，由于hadoop如果用于实时查询效率低下，
        因此将数据同步到RDS，在RDS中展示数据，效率会高很多，同时将维度值都加上索引，
        能够提高数据搜索的效率。
      </p>
      <p>
        将分级处理的表，如果有高效提取续期，则将每一级的表都同步到数据库中，
        这样能够帮助BI系统快速地展示，当涉及到下钻时，根据下钻的要求去上一级表中将下钻结果展示出来，
        提高了提取效率。
      </p>
      <p>
        删除RDS中不常用的历史数据，对于BI系统而言，有时候不需要过渡展示历史数据，
        我们已经将数据保存在hadoop中，如果有必要可以随时将这部分数据同步到RDS中，
        对于一些粒度较细的结果表，BI系统中只展示两个月的数据，在导入新的一天的数据时，
        我会在导完以后加入delete操作，及时删除历史数据。保证重要结果表查询效率。
      </p>
    </div>
  </div>
</template>

<script>
  export default {
    name: 'HelloWorld',
    data () {
      return {
        msg: 'Welcome to Your Vue.js App'
      }
    },
    methods:{

    }
  }
</script>

<!-- Add "scoped" attribute to limit CSS to this component only -->
<style scoped lang="less">
  .article{
    font-size: 16px;
    text-align: left;
    padding: 0px 20px;
    box-sizing: border-box;
    .title-main{
      .time{
        font-size: 12px;
        color: #858585;
      }
    }
    .content{
      border-top: 1px solid #CCC;
      word-wrap:break-word ;
      p{
        font-size: 16px;
      }
      img{
        display: block;
        margin: 0 auto;
        max-width: 600px;
      }
    }
  }


</style>
